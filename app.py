import streamlit as st
import base64
from langchain_groq import ChatGroq
from langchain_core.messages import HumanMessage, SystemMessage

# 1. Configurare Pagin캒
st.set_page_config(page_title="Profesorul de Mate AI", page_icon="游늻")
st.title("游늻 Proful de Mate - Rezolv캒 din Poze")

# 2. Configurare API Key
# 칉nt칙i caut캒 칥n secretele Streamlit, dac캒 nu, cere 칥n sidebar
if "GROQ_API_KEY" in st.secrets:
    api_key = st.secrets["GROQ_API_KEY"]
else:
    api_key = st.sidebar.text_input("Introdu cheia Groq API:", type="password")

if not api_key:
    st.info("Te rog introdu cheia API 칥n meniul din st칙nga pentru a 칥ncepe.")
    st.stop()

# 3. Ini탵ializarea Modelului VISION (ACTUALIZAT)
# Folosim modelul 90b care este activ 탳i foarte bun la logic캒 vizual캒
try:
    llm = ChatGroq(
        temperature=0.1,  # Temperatur캒 mic캒 pentru precizie la mate
        groq_api_key=api_key, 
        model_name="llama-3.2-90b-vision-preview" 
    )
except Exception as e:
    st.error(f"Eroare la conectare: {e}")
    st.stop()

# Func탵ie pentru a transforma imaginea 칥n text (Base64) pentru AI
def encode_image(uploaded_file):
    return base64.b64encode(uploaded_file.getvalue()).decode('utf-8')

# 4. Bara Lateral캒 pentru Upload
st.sidebar.header("Ai o problem캒 칥n caiet?")
uploaded_file = st.sidebar.file_uploader("칉ncarc캒 o poz캒 (JPG/PNG)", type=["jpg", "jpeg", "png"])

image_data = None
if uploaded_file:
    # Afi탳캒m imaginea mic캒 칥n st칙nga
    st.sidebar.image(uploaded_file, caption="Imaginea ta", use_container_width=True)
    # O proces캒m pentru AI
    image_data = encode_image(uploaded_file)
    st.sidebar.success("Imagine 칥nc캒rcat캒 cu succes! Acum 칥ntreab캒 ceva.")

# 5. Istoricul chat-ului
if "messages" not in st.session_state:
    st.session_state["messages"] = [
        {"role": "assistant", "content": "Salut! Sunt profesorul t캒u de matematic캒. Po탵i s캒-mi scrii o problem캒 sau s캒 칥ncarci o poz캒 cu ea 탳i te ajut s캒 o rezolvi pas cu pas."}
    ]

# Afi탳캒m mesajele anterioare
for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

# 6. Procesarea Inputului Utilizatorului
user_input = st.chat_input("Scrie aici (ex: 'Rezolv캒 exerci탵iul din poz캒')...")

if user_input:
    # 1. Afi탳캒m ce a scris utilizatorul
    st.session_state.messages.append({"role": "user", "content": user_input})
    st.chat_message("user").write(user_input)

    # 2. Preg캒tim instruc탵iunile pentru Profesor (System Prompt)
    system_prompt = """E탳ti un profesor de matematic캒 expert, r캒bd캒tor 탳i pedagogic.
    
    REGULI:
    1. Dac캒 prime탳ti o imagine, transcrie mental problema 탳i rezolv-o.
    2. Nu da doar r캒spunsul final. Explic캒 logica pas cu pas.
    3. Folose탳te limba rom칙n캒.
    4. Dac캒 poza este neclar캒, spune-i elevului s캒 mai fac캒 una.
    5. Folose탳te formatare clar캒 (Markdown) 탳i LaTeX pentru formule matematice (칥ncadrate de $).
    """

    # 3. Construim pachetul de mesaje pentru AI
    messages_payload = [SystemMessage(content=system_prompt)]
    
    # Construim mesajul utilizatorului (Text + Imagine Op탵ional캒)
    content_blocks = [{"type": "text", "text": user_input}]
    
    if image_data:
        content_blocks.append({
            "type": "image_url",
            "image_url": {"url": f"data:image/jpeg;base64,{image_data}"}
        })
        # Notificare discret캒 c캒 se uit캒 la poz캒
        with st.spinner("M캒 uit la poz캒 탳i calculez..."):
            pass
    
    messages_payload.append(HumanMessage(content=content_blocks))

    # 4. Gener캒m r캒spunsul
    with st.chat_message("assistant"):
        try:
            response = llm.invoke(messages_payload)
            st.write(response.content)
            # Salv캒m r캒spunsul 칥n istoric
            st.session_state.messages.append({"role": "assistant", "content": response.content})
        except Exception as e:
            st.error(f"Eroare la generare: {e}")
            # Dac캒 modelul crap캒 iar, afi탳캒m un mesaj util
            if "model_decommissioned" in str(e):
                st.warning("Modelul AI a fost actualizat de Groq. Verific캒 app.py pentru noul nume.")
