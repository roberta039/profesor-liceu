import streamlit as st
import base64
from langchain_groq import ChatGroq
from langchain_core.messages import HumanMessage, SystemMessage

# 1. Configurare PaginÄƒ
st.set_page_config(page_title="Profesorul de Mate AI (Vision)", page_icon="ğŸ“¸")
st.title("ğŸ“¸ Proful de Mate - RezolvÄƒ din Poze")

# 2. Configurare API Key
if "GROQ_API_KEY" in st.secrets:
    api_key = st.secrets["GROQ_API_KEY"]
else:
    api_key = st.sidebar.text_input("Introdu cheia Groq API:", type="password")

if not api_key:
    st.warning("Te rog introdu cheia API sau configureazÄƒ Secrets.")
    st.stop()

# 3. IniÈ›ializarea Modelului VISION
# IMPORTANT: Folosim modelul Llama 3.2 Vision Preview care "vede" imagini
try:
    llm = ChatGroq(
        temperature=0.3, 
        groq_api_key=api_key, 
        model_name="llama-3.2-11b-vision-preview" 
    )
except Exception as e:
    st.error(f"Eroare la conectare: {e}")
    st.stop()

# FuncÈ›ie pentru transformarea imaginii Ã®n format text (Base64)
def encode_image(uploaded_file):
    return base64.b64encode(uploaded_file.getvalue()).decode('utf-8')

# 4. Bara LateralÄƒ pentru Upload
st.sidebar.header("ÃncarcÄƒ o problemÄƒ")
uploaded_file = st.sidebar.file_uploader("Pune o pozÄƒ cu exerciÈ›iul (JPG/PNG)", type=["jpg", "jpeg", "png"])

# AfiÈ™area imaginii Ã®n sidebar dacÄƒ existÄƒ
image_data = None
if uploaded_file:
    st.sidebar.image(uploaded_file, caption="Imagine Ã®ncÄƒrcatÄƒ", use_container_width=True)
    image_data = encode_image(uploaded_file)

# 5. Istoricul chat-ului
if "messages" not in st.session_state:
    st.session_state["messages"] = [
        {"role": "assistant", "content": "Salut! PoÈ›i sÄƒ Ã®mi scrii problema sau sÄƒ Ã®ncarci o pozÄƒ cu ea Ã®n meniul din stÃ¢nga."}
    ]

for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

# 6. Procesarea Inputului
user_input = st.chat_input("ÃntreabÄƒ ceva despre problemÄƒ...")

if user_input:
    # AfiÈ™Äƒm mesajul utilizatorului
    st.session_state.messages.append({"role": "user", "content": user_input})
    st.chat_message("user").write(user_input)

    # Construim mesajul pentru AI
    messages_payload = []
    
    # AdÄƒugÄƒm instrucÈ›iunile de profesor (System Prompt)
    system_prompt = """EÈ™ti un profesor de matematicÄƒ expert. 
    1. AnalizeazÄƒ cu atenÈ›ie textul sau imaginea primitÄƒ.
    2. DacÄƒ e o imagine, extrage textul matematic din ea È™i rezolvÄƒ pas cu pas.
    3. ExplicÄƒ pedagogic, Ã®n limba romÃ¢nÄƒ.
    4. FoloseÈ™te LaTeX pentru formule matematice clare."""
    
    messages_payload.append(SystemMessage(content=system_prompt))

    # Construim mesajul utilizatorului (Text + Imagine dacÄƒ existÄƒ)
    content_blocks = [{"type": "text", "text": user_input}]
    
    if image_data:
        # AdÄƒugÄƒm imaginea la mesaj doar dacÄƒ utilizatorul a Ã®ncÄƒrcat una
        content_blocks.append({
            "type": "image_url",
            "image_url": {"url": f"data:image/jpeg;base64,{image_data}"}
        })
        st.info("Analizez imaginea Ã®ncÄƒrcatÄƒ... ğŸ§ ")
    
    messages_payload.append(HumanMessage(content=content_blocks))

    # GenerÄƒm rÄƒspunsul
    with st.chat_message("assistant"):
        try:
            response = llm.invoke(messages_payload)
            st.write(response.content)
            st.session_state.messages.append({"role": "assistant", "content": response.content})
        except Exception as e:
            st.error(f"A apÄƒrut o eroare: {e}")

    # ResetÄƒm imaginea dupÄƒ ce a fost analizatÄƒ (opÈ›ional, ca sÄƒ nu o trimitÄƒ la nesfÃ¢rÈ™it)
    # DacÄƒ vrei sÄƒ pÄƒstrezi imaginea pentru conversaÈ›ie continuÄƒ, È™terge liniile de mai jos.
    # if image_data:
    #     st.sidebar.success("Imagine analizatÄƒ!")
